<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Mission &mdash; ZetaBank - Instructor Version</title>
      <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/toc_custom.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/sphinxcontrib-images\LightBox2\lightbox2\dist\css\lightbox.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/sphinxcontrib-images\LightBox2\lightbox2\dist\css\lightbox.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/sphinxcontrib-images\LightBox2\lightbox2\dist\css\lightbox.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/sphinxcontrib-images\LightBox2\lightbox2\dist\css\lightbox.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/sphinxcontrib-images\LightBox2\lightbox2\dist\css\lightbox.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/sphinxcontrib-images\LightBox2\lightbox2\dist\css\lightbox.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/sphinxcontrib-images\LightBox2\lightbox2\dist\css\lightbox.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/sphinxcontrib-images\LightBox2\lightbox2\dist\css\lightbox.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/sphinxcontrib-images\LightBox2\lightbox2\dist\css\lightbox.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/sphinxcontrib-images\LightBox2\lightbox2\dist\css\lightbox.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/sphinxcontrib-images\LightBox2\lightbox2\dist\css\lightbox.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/sphinxcontrib-images\LightBox2\lightbox2\dist\css\lightbox.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/sphinxcontrib-images\LightBox2\lightbox2\dist\css\lightbox.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/sphinxcontrib-images\LightBox2\lightbox2\dist\css\lightbox.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/toc_custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script src="../../../_static/sphinx_highlight.js"></script>
        <script src="../../../_static/sphinxcontrib-images\LightBox2\lightbox2\dist\js\lightbox-plus-jquery.min.js"></script>
        <script src="../../../_static/sphinxcontrib-images\LightBox2\lightbox2-customize\jquery-noconflict.js"></script>
        <script src="../../../_static/sphinxcontrib-images\LightBox2\lightbox2\dist\js\lightbox-plus-jquery.min.js"></script>
        <script src="../../../_static/sphinxcontrib-images\LightBox2\lightbox2-customize\jquery-noconflict.js"></script>
        <script src="../../../_static/sphinxcontrib-images\LightBox2\lightbox2\dist\js\lightbox-plus-jquery.min.js"></script>
        <script src="../../../_static/sphinxcontrib-images\LightBox2\lightbox2-customize\jquery-noconflict.js"></script>
        <script src="../../../_static/sphinxcontrib-images\LightBox2\lightbox2\dist\js\lightbox-plus-jquery.min.js"></script>
        <script src="../../../_static/sphinxcontrib-images\LightBox2\lightbox2-customize\jquery-noconflict.js"></script>
        <script src="../../../_static/sphinxcontrib-images\LightBox2\lightbox2\dist\js\lightbox-plus-jquery.min.js"></script>
        <script src="../../../_static/sphinxcontrib-images\LightBox2\lightbox2-customize\jquery-noconflict.js"></script>
        <script src="../../../_static/sphinxcontrib-images\LightBox2\lightbox2\dist\js\lightbox-plus-jquery.min.js"></script>
        <script src="../../../_static/sphinxcontrib-images\LightBox2\lightbox2-customize\jquery-noconflict.js"></script>
        <script src="../../../_static/sphinxcontrib-images\LightBox2\lightbox2\dist\js\lightbox-plus-jquery.min.js"></script>
        <script src="../../../_static/sphinxcontrib-images\LightBox2\lightbox2-customize\jquery-noconflict.js"></script>
        <script src="../../../_static/sphinxcontrib-images\LightBox2\lightbox2\dist\js\lightbox-plus-jquery.min.js"></script>
        <script src="../../../_static/sphinxcontrib-images\LightBox2\lightbox2-customize\jquery-noconflict.js"></script>
        <script src="../../../_static/sphinxcontrib-images\LightBox2\lightbox2\dist\js\lightbox-plus-jquery.min.js"></script>
        <script src="../../../_static/sphinxcontrib-images\LightBox2\lightbox2-customize\jquery-noconflict.js"></script>
        <script src="../../../_static/sphinxcontrib-images\LightBox2\lightbox2\dist\js\lightbox-plus-jquery.min.js"></script>
        <script src="../../../_static/sphinxcontrib-images\LightBox2\lightbox2-customize\jquery-noconflict.js"></script>
        <script src="../../../_static/sphinxcontrib-images\LightBox2\lightbox2\dist\js\lightbox-plus-jquery.min.js"></script>
        <script src="../../../_static/sphinxcontrib-images\LightBox2\lightbox2-customize\jquery-noconflict.js"></script>
        <script src="../../../_static/sphinxcontrib-images\LightBox2\lightbox2\dist\js\lightbox-plus-jquery.min.js"></script>
        <script src="../../../_static/sphinxcontrib-images\LightBox2\lightbox2-customize\jquery-noconflict.js"></script>
        <script src="../../../_static/sphinxcontrib-images\LightBox2\lightbox2\dist\js\lightbox-plus-jquery.min.js"></script>
        <script src="../../../_static/sphinxcontrib-images\LightBox2\lightbox2-customize\jquery-noconflict.js"></script>
        <script src="../../../_static/sphinxcontrib-images\LightBox2\lightbox2\dist\js\lightbox-plus-jquery.min.js"></script>
        <script src="../../../_static/sphinxcontrib-images\LightBox2\lightbox2-customize\jquery-noconflict.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Discussion" href="6.discussion.html" />
    <link rel="prev" title="Coding Explanation" href="4.coding_explanation.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../index.html" class="icon icon-home">
            Elementary Version
              <img src="../../../_static/logo.png" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                0.1.3
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Day1</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../Day1/0.index.html">Enjoy AI robot with body</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../Day1/2.exploration.html">AI Exploration Education</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Day2</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../../0.index.html">Enjoy AI robot with eyes</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="../0.index.html">AI training with the body and eyes</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="../1.object_detect/1.index.html">Object Detection with COCO-Dog</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../1.object_detect/2.follow_along.html">Follow Along!</a></li>
<li class="toctree-l4"><a class="reference internal" href="../1.object_detect/3.explanation.html">Overall Explanation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../1.object_detect/4.coding_explanation.html">Coding Explanation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../1.object_detect/5.mission.html">Mission</a></li>
<li class="toctree-l4"><a class="reference internal" href="../1.object_detect/6.discussion.html">Discussion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../2.tao_peoplenet/1.index.html">Tao Peoplenet Examples</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../2.tao_peoplenet/2.follow_along.html">Follow Along!</a></li>
<li class="toctree-l4"><a class="reference internal" href="../2.tao_peoplenet/3.explanation.html">Overall Explanation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../2.tao_peoplenet/4.coding_explanation.html">Coding Explanation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../2.tao_peoplenet/5.mission.html">Mission</a></li>
<li class="toctree-l4"><a class="reference internal" href="../2.tao_peoplenet/6.discussion.html">Discussion</a></li>
</ul>
</li>
<li class="toctree-l3 current"><a class="reference internal" href="1.index.html">Sematic Segmentation Examples</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="2.follow_along.html">Follow Along!</a></li>
<li class="toctree-l4"><a class="reference internal" href="3.explanation.html">Overall Explanation</a></li>
<li class="toctree-l4"><a class="reference internal" href="4.coding_explanation.html">Coding Explanation</a></li>
<li class="toctree-l4 current"><a class="current reference internal" href="#">Mission</a></li>
<li class="toctree-l4"><a class="reference internal" href="6.discussion.html">Discussion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../4.posenet/1.index.html">Body Pose Estimation with Pose-ResNet18-Body</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../4.posenet/2.follow_along.html">Follow Along!</a></li>
<li class="toctree-l4"><a class="reference internal" href="../4.posenet/3.explanation.html">Overall Explanation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../4.posenet/4.coding_explanation.html">Coding Explanation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../4.posenet/5.mission.html">Mission</a></li>
<li class="toctree-l4"><a class="reference internal" href="../4.posenet/6.discussion.html">Discussion</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../4.autonomous.html">Team mission autonomous driving</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../1.robot_arm/0.index.html">Control AI Robot Arm</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../1.robot_arm/1.follow_along.html">Follow Along!</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../1.robot_arm/2.mission.html">Mission</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../2.arm_dance/0.index.html">Dance with AI Robot Arm</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../2.arm_dance/1.follow_along.html">Follow Along!</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../2.arm_dance/2.mission.html">Mission</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../3.control_move/0.index.html">Control AI Robot</a><ul class="simple">
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../4.control_sensor/0.index.html">Monitor AI Robot Sensor</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../4.control_sensor/1.follow_along.html">Follow Along!</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../5.control_team/0.index.html">Control AI Robot as a Team</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../5.control_team/1.follow_along.html">Follow Along!</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Day3</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../Day3/0.index.html">Discuss AI robots</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../Day3/2.presentation.html">Presentation and discussion</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">Elementary Version</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../0.index.html">Enjoy AI robot with eyes</a></li>
          <li class="breadcrumb-item"><a href="../0.index.html">AI training with the body and eyes</a></li>
          <li class="breadcrumb-item"><a href="1.index.html">Sematic Segmentation Examples</a></li>
      <li class="breadcrumb-item active">Mission</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../_sources/Day2/2.AI/3.segmentation/5.mission.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="mission">
<h1>Mission<a class="headerlink" href="#mission" title="Permalink to this heading"></a></h1>
<div style="background: #ffe5b4" class="admonition note custom">
    <p style="background: #ffbf00" class="admonition-title">
        Project Name: Custom Segmentation System
    </p>
    <div class="line-block">
        <div class="line"><strong>-</strong> This mission is an <strong>individual project</strong></div>
        <div class="line"><strong>-</strong> Create the custom segmetation program which utilizes zetabot camera.</div>
        <div class="line"><strong>-</strong> Within your individual computers, execute the following mission.  </div>
    </div>
</div><section id="writing-custom-segnet-program">
<h2>Writing Custom segNet Program<a class="headerlink" href="#writing-custom-segnet-program" title="Permalink to this heading"></a></h2>
<p class="linemarker linemarker-21">Similar to how we created a new python file in our team assignment, generate a new python file and name it <code class="docutils literal notranslate"><span class="pre">02_5-2.</span> <span class="pre">segmentation_camera.py</span></code>.</p>
<p class="linemarker linemarker-23">Create a new python file in the Jupyter Notebook Environment:</p>
<ul>
<li><p class="linemarker linemarker-25">Press the blue plus button on the top left corner of the web.</p>
<a class=""
               data-lightbox="group-4bfda7a6-bf36-4756-8918-b4b590e93e64"
               href="_images/ai_training/add_plus.png"
               title=""
               data-title=""
               
               ><img src="_images/ai_training/add_plus.png"
                     class=""
                     width="100%"
                     height="auto"
                     alt=""/>
                </a></li>
</ul>
<div class="line-block">
<div class="line"><br /></div>
</div>
<ul>
<li><p class="linemarker linemarker-31">Create a new python file by pressing the <code class="docutils literal notranslate"><span class="pre">Python</span> <span class="pre">File</span></code> button</p>
<a class=""
               data-lightbox="group-5517d30d-d3ad-4c60-af6e-4c7efdff961f"
               href="_images/ai_training/pick_python.png"
               title=""
               data-title=""
               
               ><img src="_images/ai_training/pick_python.png"
                     class=""
                     width="100%"
                     height="auto"
                     alt=""/>
                </a></li>
</ul>
<div class="line-block">
<div class="line"><br /></div>
</div>
<ul>
<li><p class="linemarker linemarker-37">Rename the untitiled python file to <code class="docutils literal notranslate"><span class="pre">02_5-2.</span> <span class="pre">segmentation_camera.py</span></code></p></li>
<li><p class="linemarker linemarker-40">On the new python file, import the libraries necessary. For our segmentation task, we need to import the Jetson inference library modules and jetson utility library modules</p>
<ul class="simple">
<li><p class="linemarker linemarker-42"><code class="docutils literal notranslate"><span class="pre">argparse</span></code>: This library contains modules that are responsbile for bringing and intitializing the flags or parameters set by the user when envoking the program.</p></li>
<li><p class="linemarker linemarker-43"><code class="docutils literal notranslate"><span class="pre">sys</span></code>: this library allows us to manipulate/ utilize system functions within our python programs.</p></li>
<li><p class="linemarker linemarker-45"><code class="docutils literal notranslate"><span class="pre">jetson_inference</span></code>: This library contains all the pre-built networks that can be used for inference task and a functions that would allow for custom models to be used for inference tasks.</p>
<ul>
<li><p class="linemarker linemarker-47"><code class="docutils literal notranslate"><span class="pre">setNet</span></code>: We are importing segNet module for our segmentation task.</p></li>
</ul>
</li>
<li><p class="linemarker linemarker-50"><code class="docutils literal notranslate"><span class="pre">jetson_utils</span></code>: This library contains modules that are responsible for processing input and output sources along with output stream methods. We will be importing the following modules:</p>
<ul>
<li><p class="linemarker linemarker-52"><code class="docutils literal notranslate"><span class="pre">videoSource</span></code>: used to process input source (whether it is a camera, an image, or a video).</p></li>
<li><p class="linemarker linemarker-53"><code class="docutils literal notranslate"><span class="pre">videoOutput</span></code>: used to process the output stream.</p></li>
<li><p class="linemarker linemarker-54"><code class="docutils literal notranslate"><span class="pre">cudaOverlay</span></code>: this module allows for overlay on the output stream.</p></li>
<li><p class="linemarker linemarker-55"><code class="docutils literal notranslate"><span class="pre">cudaDeviceSynchronize</span></code>: This module allows for cuda devices and processes to synchronize.</p></li>
</ul>
</li>
<li><p class="linemarker linemarker-57"><code class="docutils literal notranslate"><span class="pre">segnet_utils</span></code>: This library allows for buffer segmentation methods.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">argparse</span>
<span class="kn">import</span> <span class="nn">sys</span>

<span class="kn">from</span> <span class="nn">jetson_inference</span> <span class="kn">import</span> <span class="n">segNet</span>
<span class="kn">from</span> <span class="nn">jetson_utils</span> <span class="kn">import</span> <span class="n">videoSource</span><span class="p">,</span> <span class="n">videoOutput</span><span class="p">,</span> <span class="n">cudaOverlay</span><span class="p">,</span> <span class="n">cudaDeviceSynchronize</span>

<span class="kn">from</span> <span class="nn">segnet_utils</span> <span class="kn">import</span> <span class="o">*</span>
</pre></div>
</div>
</li>
<li><p class="linemarker linemarker-70">After all the libraries are imported, initialize the parser variable with <code class="docutils literal notranslate"><span class="pre">argparse.ArgumentParser</span></code> module.</p>
<p class="linemarker linemarker-72">For our mission, we must receive the network name, and Camera output channel name. Additionally we add our minor functinoality flags.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># parse the command line</span>
<span class="c1"># For our mission, We recieve the network name, and Camera name.</span>
<span class="c1"># Set up argument parser, so that command line parameters can be read within the program</span>
<span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="s2">&quot;Segment a live camera stream using an semantic segmentation DNN.&quot;</span><span class="p">,</span>
                                <span class="n">formatter_class</span><span class="o">=</span><span class="n">argparse</span><span class="o">.</span><span class="n">RawTextHelpFormatter</span><span class="p">,</span>
                                <span class="n">epilog</span><span class="o">=</span><span class="n">segNet</span><span class="o">.</span><span class="n">Usage</span><span class="p">()</span> <span class="o">+</span> <span class="n">videoSource</span><span class="o">.</span><span class="n">Usage</span><span class="p">()</span> <span class="o">+</span> <span class="n">videoOutput</span><span class="o">.</span><span class="n">Usage</span><span class="p">())</span>

<span class="c1"># Major Functionality parameters (required from the user)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;input_CAMERA&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">nargs</span><span class="o">=</span><span class="s1">&#39;?&#39;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;use csi://0 for Raspberry pi Camera&quot;</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--network&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;pre-trained model to load&quot;</span><span class="p">)</span>

<span class="c1"># Minor Functionality parameters (optional)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--filter-mode&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">,</span> <span class="n">choices</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;point&quot;</span><span class="p">,</span> <span class="s2">&quot;linear&quot;</span><span class="p">],</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;filtering mode used during visualization, options are:</span><span class="se">\n</span><span class="s2">  &#39;point&#39; or &#39;linear&#39; (default: &#39;linear&#39;)&quot;</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--visualize&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;overlay,mask&quot;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Visualization options (can be &#39;overlay&#39; &#39;mask&#39; &#39;overlay,mask&#39;&quot;</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--ignore-class&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;void&quot;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;optional name of class to ignore in the visualization results (default: &#39;void&#39;)&quot;</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--alpha&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">150.0</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;alpha blending value to use during overlay, between 0.0 and 255.0 (default: 150.0)&quot;</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--stats&quot;</span><span class="p">,</span> <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;compute statistics about segmentation mask class output&quot;</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p class="linemarker linemarker-95">Initialize opt variable to hold all the user-set flags in a list form. If the user has set no flags, terminate the program:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># If no parameter is given from the user, shut the program down</span>
<span class="k">try</span><span class="p">:</span>
    <span class="n">opt</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_known_args</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
<span class="k">except</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">print_help</span><span class="p">()</span>
    <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p class="linemarker linemarker-107">Initialize the necessary variables. Since we wish to infer a network with a camera and show the results with our output stream we will need:</p>
<ol class="arabic simple">
<li><p class="linemarker linemarker-109"><code class="docutils literal notranslate"><span class="pre">net</span></code> variable for holding the nvidia pre-built networks. For this mission we are using FCN-Resnet18-VOC (you may change this to FCN-ResNet18-Sun for indoor segmentation) network.</p></li>
<li><p class="linemarker linemarker-110"><code class="docutils literal notranslate"><span class="pre">input</span></code> variable for handling the input stream. Using the <code class="docutils literal notranslate"><span class="pre">opt</span></code> variable created in our previous step, we will bring in input_CAMERA to set our videoSource.</p></li>
<li><p class="linemarker linemarker-111"><code class="docutils literal notranslate"><span class="pre">display</span></code> variable for handling the output stream. Although we are accessing the code remotely on our remote computer, the zetabot is equipped with a touch screen display. The display is set on <code class="docutils literal notranslate"><span class="pre">DISPLAY://0</span></code></p></li>
<li><p class="linemarker linemarker-112"><code class="docutils literal notranslate"><span class="pre">buffer</span></code> variable for managing buffer.</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># load the segmentation network</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">segNet</span><span class="p">(</span><span class="n">opt</span><span class="o">.</span><span class="n">network</span><span class="p">,</span> <span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">)</span>

<span class="c1"># set the alpha blending value</span>
<span class="n">net</span><span class="o">.</span><span class="n">SetOverlayAlpha</span><span class="p">(</span><span class="n">opt</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span>

<span class="c1"># create video sources &amp; outputs</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">videoSource</span><span class="p">(</span><span class="n">opt</span><span class="o">.</span><span class="n">input_CAMERA</span><span class="p">,</span> <span class="n">argv</span><span class="o">=</span><span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">videoOutput</span><span class="p">(</span><span class="s2">&quot;DISPLAY://0&quot;</span><span class="p">,</span> <span class="n">argv</span><span class="o">=</span><span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">)</span>
<span class="c1"># create buffer manager</span>
<span class="n">buffers</span> <span class="o">=</span> <span class="n">segmentationBuffers</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">opt</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p class="linemarker linemarker-128">For this task we are utilizing our camera. On our previous trials, we had to to an inference on a single image. The program could recieve the one image infer it with the network and output a single result.</p>
<p class="linemarker linemarker-130">But with a camera, we need to repeatedly run the inference so that we may capture the incoming frames from the camera and output a constant stream of results.</p>
<ul>
<li><p class="linemarker linemarker-132">We may achieve this by running a while loop until an envoked output stream window is killed by the user.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># process frames until the user exits</span>
<span class="k">while</span> <span class="n">display</span><span class="o">.</span><span class="n">IsStreaming</span><span class="p">():</span>
</pre></div>
</div>
</li>
<li><p class="linemarker linemarker-139">Within the while loop:</p>
<ul>
<li><p class="linemarker linemarker-141">Capture the current frame from the camera, allocate buffer for the size of the camera and infer the image using the trained model.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Capture each of the frames of camera</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">camera</span><span class="o">.</span><span class="n">Capture</span><span class="p">()</span>

<span class="c1"># allocate buffers for this size image</span>
<span class="n">buffers</span><span class="o">.</span><span class="n">Alloc</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">img</span><span class="o">.</span><span class="n">format</span><span class="p">)</span>

<span class="c1"># process the segmentation network</span>
<span class="n">net</span><span class="o">.</span><span class="n">Process</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">ignore_class</span><span class="o">=</span><span class="n">opt</span><span class="o">.</span><span class="n">ignore_class</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p class="linemarker linemarker-154">Overlay the resulting heatmap and mask with with the buffer.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># generate the overlay</span>
<span class="k">if</span> <span class="n">buffers</span><span class="o">.</span><span class="n">overlay</span><span class="p">:</span>
    <span class="n">net</span><span class="o">.</span><span class="n">Overlay</span><span class="p">(</span><span class="n">buffers</span><span class="o">.</span><span class="n">overlay</span><span class="p">,</span> <span class="n">filter_mode</span><span class="o">=</span><span class="n">opt</span><span class="o">.</span><span class="n">filter_mode</span><span class="p">)</span>

<span class="c1"># generate the mask</span>
<span class="k">if</span> <span class="n">buffers</span><span class="o">.</span><span class="n">mask</span><span class="p">:</span>
    <span class="n">net</span><span class="o">.</span><span class="n">Mask</span><span class="p">(</span><span class="n">buffers</span><span class="o">.</span><span class="n">mask</span><span class="p">,</span> <span class="n">filter_mode</span><span class="o">=</span><span class="n">opt</span><span class="o">.</span><span class="n">filter_mode</span><span class="p">)</span>

<span class="c1"># composite the images</span>
<span class="k">if</span> <span class="n">buffers</span><span class="o">.</span><span class="n">composite</span><span class="p">:</span>
    <span class="n">cudaOverlay</span><span class="p">(</span><span class="n">buffers</span><span class="o">.</span><span class="n">overlay</span><span class="p">,</span> <span class="n">buffers</span><span class="o">.</span><span class="n">composite</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">cudaOverlay</span><span class="p">(</span><span class="n">buffers</span><span class="o">.</span><span class="n">mask</span><span class="p">,</span> <span class="n">buffers</span><span class="o">.</span><span class="n">composite</span><span class="p">,</span> <span class="n">buffers</span><span class="o">.</span><span class="n">overlay</span><span class="o">.</span><span class="n">width</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p class="linemarker linemarker-171">Render the result output and update the title bar of the output window.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># render the output image</span>
<span class="n">output</span><span class="o">.</span><span class="n">Render</span><span class="p">(</span><span class="n">buffers</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>

<span class="c1"># update the title bar</span>
<span class="n">output</span><span class="o">.</span><span class="n">SetStatus</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:s}</span><span class="s2"> | Network </span><span class="si">{:.0f}</span><span class="s2"> FPS&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">opt</span><span class="o">.</span><span class="n">network</span><span class="p">,</span> <span class="n">net</span><span class="o">.</span><span class="n">GetNetworkFPS</span><span class="p">()))</span>
</pre></div>
</div>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</section>
<section id="executing-the-custom-program">
<h2>Executing the Custom Program<a class="headerlink" href="#executing-the-custom-program" title="Permalink to this heading"></a></h2>
<ul class="simple">
<li><p class="linemarker linemarker-186">Open the <code class="docutils literal notranslate"><span class="pre">02_5-3.</span> <span class="pre">segmentation_camera.ipynb</span></code> notebook.</p></li>
</ul>
<a class=""
               data-lightbox="group-baef44e7-ba26-4b9b-97cd-d99bd7eb6300"
               href="_images/course_3/3.ai_segmentation_depth/segmentation_camera.png"
               title=""
               data-title=""
               
               ><img src="_images/course_3/3.ai_segmentation_depth/segmentation_camera.png"
                     class=""
                     width="100%"
                     height="auto"
                     alt=""/>
                </a><div class="line-block">
<div class="line"><br /></div>
</div>
<ul>
<li><p class="linemarker linemarker-192">Run the cell code which initializes the input/ output stream of the environment as well as the CAMERA variable, which will be the flag that determines the input vairable for the program to be a camera stream.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="n">env</span> <span class="n">DISPLAY</span><span class="o">=</span><span class="p">:</span><span class="mi">0</span>
<span class="o">%</span><span class="n">env</span> <span class="n">csi</span><span class="o">=</span><span class="p">:</span><span class="mi">0</span>
<span class="o">%</span><span class="n">env</span> <span class="n">CAMERA</span><span class="o">=</span><span class="n">csi</span><span class="p">:</span><span class="o">//</span><span class="mi">0</span>
</pre></div>
</div>
</li>
<li><p class="linemarker linemarker-200">Check if your python notebook can read the python code you have written:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>!cat /home/zeta/notebook/lecture/&#39;2.AI Training Examples&#39;/&#39;5-2. segmentation_camera.py&#39;
</pre></div>
</div>
</li>
<li><p class="linemarker linemarker-206">One important thing about the zetabot is that the Raspberry Pi camera is constantly running.</p>
<p class="linemarker linemarker-208">In order to use the camera for our task we must disable it first by running the following command:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>%%capture
!pm2 stop 5
</pre></div>
</div>
<p class="linemarker linemarker-215">This will allow the camera to be used for our program.</p>
</li>
<li><p class="linemarker linemarker-217">Execute the segmentation_camera python code.</p>
<p class="linemarker linemarker-219"><em>Note</em> that we are setting our major functions,</p>
<ul class="simple">
<li><p class="linemarker linemarker-221"><code class="docutils literal notranslate"><span class="pre">--network</span></code>: to set which networks to use in our segmentation task.</p>
<ul>
<li><p class="linemarker linemarker-223">You may change the pre-trained networks to the previously discussed networks.</p></li>
</ul>
</li>
<li><p class="linemarker linemarker-225"><code class="docutils literal notranslate"><span class="pre">input_CAMERA</span></code>: to set which input stream will be used for our task. It is being set to CAMERA environment variable which holds <code class="docutils literal notranslate"><span class="pre">csi://0</span></code> as a string.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>%%capture
!python3 /home/zeta/notebook/lecture/&#39;2.AI Training Examples&#39;/&#39;5-2. segmentation_camera.py&#39; --network=fcn-resnet18-voc $CAMERA
</pre></div>
</div>
</li>
<li><p class="linemarker linemarker-232">Be sure to turn the camera back online by:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>%%capture
!pm2 start 5
</pre></div>
</div>
</li>
</ul>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="4.coding_explanation.html" class="btn btn-neutral float-left" title="Coding Explanation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="6.discussion.html" class="btn btn-neutral float-right" title="Discussion" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright .</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
    <!-- Theme Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-17821189-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-17821189-2', {
          'anonymize_ip': false,
      });
    </script> 

</body>
</html>