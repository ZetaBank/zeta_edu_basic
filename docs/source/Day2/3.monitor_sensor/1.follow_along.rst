Follow Along!
================

.. raw:: html

    <div style="background: #C3F8FF" class="admonition note custom">
        <p style="background: light-blue" class="admonition-title">
            Project Name: Robot Sensor Visualization
        </p>
        <div class="line-block">
            <div class="line"><strong>-</strong> This mission is an <strong>individual project</strong></div>
            <div class="line"><strong>-</strong> Access the Isaac Sight server and monitor the robot's sensors.</div>
            <div class="line"><strong>-</strong> While moving the robot, check the change amount of the sensors according to the change of the robot. </div>
        </div>
    </div>

.. raw:: html

.. thumbnail:: /_images/Day2/3.monitor_sensor/autodrive.jpg

Overall Description
-----------------------

.. list-table:: 
   :header-rows: 1

   * - Inside the Robot
     - Inside the Human
   * - |part_1| 
     - |part_6| 
   * - |part_2| 
     - |part_7| 
   * - |part_3| 
     - |part_8| 
   * - |part_4| 
     - |part_9| 
   * - |part_5| 
     - |part_10| 

.. |part_1| thumbnail:: /_images/Day2/3.monitor_sensor/parts_1.webp
.. |part_2| thumbnail:: /_images/Day2/3.monitor_sensor/parts_2.webp 
.. |part_3| thumbnail:: /_images/Day2/3.monitor_sensor/parts_3.webp 
.. |part_4| thumbnail:: /_images/Day2/3.monitor_sensor/parts_4.webp 
.. |part_5| thumbnail:: /_images/Day2/3.monitor_sensor/parts_5.jpg
.. |part_6| thumbnail:: /_images/Day2/3.monitor_sensor/brain.png
.. |part_7| thumbnail:: /_images/Day2/3.monitor_sensor/superpower.jpg
.. |part_8| thumbnail:: /_images/Day2/3.monitor_sensor/eye.png
.. |part_9| thumbnail:: /_images/Day2/3.monitor_sensor/ear.png
.. |part_10| thumbnail:: /_images/Day2/3.monitor_sensor/heart.png

The advanced ai robot zetabaot is equipped with various sensors.

sensors attached to our robot communicates over a Topic, with each sensors publishing their data to a specific Topic.

Although
we may subscribe to these specific topics and extract the published data, without proper user interface, it is hard to decipher what the values 
mean just by looking at them. 

In order to illustrate what the sensors are publishing to the topics, we use a visualization service called the isaac sight. 

Isaac Sight is a web service mounted on our Jetson Nano board. It uses a Isaac node to listen to all the Topics that are present on the machine. 

With Isaac sight we may display the odometry sensor values from position, velocity, and orientation or imu sensor values such as orientation and 
angular velocity in a graphs.

It also can display the LIDAR datas in a 2 dimensional map setting and other sensors. 


For this mission, we will access Isaac Sight, and check how the visual representations change when we move our robots. 


Accessing Isaac Sight
-----------------------

Isaac Sight web service is mounted on port:3000 and can be accessed via `<http://10.42.0.1:3000/>`_ website. Make sure that the host computer 
is connected to the zeta wifi. 

When the website is accessed, the screen similar to the following will be displayed:

.. thumbnail:: /_images/Day2/3.monitor_sensor/isaac_page.png

|

The middle of the section displays multiple windows with 2D visuals from various sensors. 
The color and other visual settings may be accessed via the pencil icon or by directly updating the setting by right clicking on the desired 
visual. 

On the left you, the Isaac Sight displays all the available channels which can be visualized. 
Activate all the available sensors and check for the visuals.


Checking Visuals
-------------------

Lets move our robot to check how the visuals of the sensors change. 